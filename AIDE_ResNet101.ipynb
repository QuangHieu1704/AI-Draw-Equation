{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIDE_ResNet101.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOqWvfaBg31J"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import os\n",
        "from tqdm.autonotebook import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential, load_model, Model \n",
        "from keras.layers import Conv2D, MaxPool2D, Add, Dense, Reshape, Flatten, Dropout, BatchNormalization, ReLU, Activation, Concatenate, Flatten, Input, Concatenate, Activation, LSTM, Bidirectional, Lambda\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "from keras import Input\n",
        "from keras import backend\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "tQscBNo6g7dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "i3ET53fUg9Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/AI Draw Equation/AIDE dataset.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "LrcTpCoOg-mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and val dataset\n",
        "list_categories = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"add\", \"dec\", \"div\", \"mul\", \"stroke\", \"sub\", \"(\", \")\"]\n",
        "train_path = \"/content/AIDE dataset/train\"\n",
        "X_train = []\n",
        "Y_train = []\n",
        "for label_folder in os.listdir(train_path):\n",
        "  curr_path = os.path.join(train_path, label_folder)\n",
        "  lbl = list_categories.index(label_folder)\n",
        "  for img_name in os.listdir(curr_path):\n",
        "    img = cv2.imread(os.path.join(curr_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, None, fx = 0.5, fy = 0.5)\n",
        "    X_train.append(img)\n",
        "    Y_train.append(int(lbl))\n",
        "X_train = np.array(X_train) / 255.0\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "val_path = \"/content/AIDE dataset/val\"\n",
        "X_val = []\n",
        "Y_val = []\n",
        "for label_folder in os.listdir(val_path):\n",
        "  curr_path = os.path.join(val_path, label_folder)\n",
        "  lbl = list_categories.index(label_folder)\n",
        "  for img_name in os.listdir(curr_path):\n",
        "    img = cv2.imread(os.path.join(curr_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, None, fx = 0.5, fy = 0.5)\n",
        "    X_val.append(img)\n",
        "    Y_val.append(int(lbl))\n",
        "X_val = np.array(X_val) / 255.0\n",
        "Y_val = np.array(Y_val)\n",
        "\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_val = to_categorical(Y_val)"
      ],
      "metadata": {
        "id": "Vn3sGf1Bg_1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of train samples: {X_train.shape[0]}\")\n",
        "print(f\"Number of val samples: {X_val.shape[0]}\")"
      ],
      "metadata": {
        "id": "pdX4H3a8hA_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "input_img = Input(shape=(112, 112 , 1), name=\"input\")\n",
        "x = Concatenate()([input_img, input_img, input_img])\n",
        "model_resnet101 = ResNet101(weights='imagenet',input_tensor = x, include_top=False)\n",
        "x = model_resnet101.output\n",
        "# x = Flatten()(x)\n",
        "# x = Dense(1028, activation='relu')(x)\n",
        "# x = Dense(512, activation='relu')(x)\n",
        "# x = Dense(128, activation='relu')(x)\n",
        "# output = Dense(18, activation='softmax')(x)\n",
        "model = Model(inputs = input_img, outputs = x)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "SvfzS3YghCZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "opt = keras.optimizers.Adam(learning_rate = lr)\n",
        "model.compile(loss='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "train = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs = 50, batch_size = 32, verbose = 1)  "
      ],
      "metadata": {
        "id": "wUnwIuRihGbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test \n",
        "test_path = \"/content/AIDE dataset/test\"\n",
        "X_test = []\n",
        "Y_test = []\n",
        "for label_folder in os.listdir(test_path):\n",
        "  curr_path = os.path.join(test_path, label_folder)\n",
        "  lbl = list_categories.index(label_folder)\n",
        "  for img_name in os.listdir(curr_path):\n",
        "    img = cv2.imread(os.path.join(curr_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, None, fx = 0.5, fy = 0.5)\n",
        "    X_test.append(img)\n",
        "    Y_test.append(int(lbl))\n",
        "X_test = np.array(X_test) / 255.0\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "Y_test = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "6BkPju7LhIS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(f\"Evaluate using GPU: {time.time() - start_time}\")\n",
        "print(\"Loss = \", test_loss)\n",
        "print(\"Evaluation Accuracy = \", test_accuracy * 100)"
      ],
      "metadata": {
        "id": "Zp1M7QBNhKTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "count = 0\n",
        "for i in range(X_test.shape[0]):\n",
        "  pred = model.predict(X_test[i].reshape(1, 112, 112, 1))\n",
        "  pred = list_categories[np.argmax(pred)]\n",
        "  true = list_categories[np.argmax(Y_test[i])]\n",
        "  if pred == true:\n",
        "    count += 1\n",
        "print(f\"Evaluate using CPU: {time.time() - start_time}\")\n",
        "print(f\"Test Accuracy: {count / X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "WjXmiv15hLdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = train.history['accuracy']\n",
        "val_accuracy = train.history['val_accuracy']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Xw3tdW4hMpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = train.history['loss']\n",
        "val_loss = train.history['val_loss']\n",
        "epochs = range(len(train_loss))\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s48pSvhDhN1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(f\"/content/gdrive/MyDrive/AI Draw Equation/Model/ResNet101 lr={lr}.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(f\"/content/gdrive/MyDrive/AI Draw Equation/Model/ResNet101 lr={lr}.h5\")"
      ],
      "metadata": {
        "id": "7jS3vF87hO0g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}