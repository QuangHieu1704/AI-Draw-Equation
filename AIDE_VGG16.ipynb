{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIDE_VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IzoNXHiYiZ91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0e3d10-a1a9-4261-90d6-2ff1d70ca44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "import os\n",
        "from tqdm.autonotebook import tqdm\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential, load_model, Model \n",
        "from keras.layers import Conv2D, MaxPool2D, Add, Dense, Reshape, Flatten, Dropout, BatchNormalization, ReLU, Activation, Concatenate, Flatten, Input, Concatenate, Activation, LSTM, Bidirectional, Lambda\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "from keras import Input\n",
        "from keras import backend\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0m5XAb-f6AG",
        "outputId": "7ff275b9-73b9-48ed-9bf6-e970d86f93f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xtq0JG9ef7z5",
        "outputId": "b151105f-34f0-4ec4-9d1a-34b89be6c720"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug  1 15:54:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/MyDrive/AI Draw Equation/AIDE dataset.zip\" -d \"/content\""
      ],
      "metadata": {
        "id": "dcMplCQ6f9Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and val dataset\n",
        "list_categories = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"add\", \"dec\", \"div\", \"mul\", \"stroke\", \"sub\", \"(\", \")\"]\n",
        "train_path = \"/content/AIDE dataset/train\"\n",
        "X_train = []\n",
        "Y_train = []\n",
        "for label_folder in os.listdir(train_path):\n",
        "  curr_path = os.path.join(train_path, label_folder)\n",
        "  lbl = list_categories.index(label_folder)\n",
        "  for img_name in os.listdir(curr_path):\n",
        "    img = cv2.imread(os.path.join(curr_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, None, fx = 0.5, fy = 0.5)\n",
        "    X_train.append(img)\n",
        "    Y_train.append(int(lbl))\n",
        "X_train = np.array(X_train) / 255.0\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "val_path = \"/content/AIDE dataset/val\"\n",
        "X_val = []\n",
        "Y_val = []\n",
        "for label_folder in os.listdir(val_path):\n",
        "  curr_path = os.path.join(val_path, label_folder)\n",
        "  lbl = list_categories.index(label_folder)\n",
        "  for img_name in os.listdir(curr_path):\n",
        "    img = cv2.imread(os.path.join(curr_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, None, fx = 0.5, fy = 0.5)\n",
        "    X_val.append(img)\n",
        "    Y_val.append(int(lbl))\n",
        "X_val = np.array(X_val) / 255.0\n",
        "Y_val = np.array(Y_val)\n",
        "\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_val = to_categorical(Y_val)"
      ],
      "metadata": {
        "id": "QdGDzN1If-9n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of train samples: {X_train.shape[0]}\")\n",
        "print(f\"Number of val samples: {X_val.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ0ukw3DHozy",
        "outputId": "d17761b4-c0db-47e5-adb9-e6943d32a387"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples: 11394\n",
            "Number of val samples: 3806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "input_img = Input(shape=(112, 112 , 1), name=\"input\")\n",
        "x = Concatenate()([input_img, input_img, input_img])\n",
        "model_vgg16 = VGG16(weights='imagenet',input_tensor = x, include_top=False)\n",
        "x = model_vgg16.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output = Dense(18, activation='softmax')(x)\n",
        "model = Model(inputs = input_img, outputs = output)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "fCTAITq5gDQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7fefe47-1085-438b-86e3-d978bc8b31d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 112, 112, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 112, 112, 3)  0           ['input[0][0]',                  \n",
            "                                                                  'input[0][0]',                  \n",
            "                                                                  'input[0][0]']                  \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 112, 112, 64  1792        ['concatenate[0][0]']            \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 112, 112, 64  36928       ['block1_conv1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 56, 56, 64)   0           ['block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 56, 56, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 56, 56, 128)  147584      ['block2_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 28, 28, 128)  0           ['block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 28, 28, 256)  295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 28, 28, 256)  590080      ['block3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 28, 28, 256)  590080      ['block3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 14, 14, 256)  0           ['block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 14, 14, 512)  1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 7, 7, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 7, 7, 512)    2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 7, 7, 512)    2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block5_pool (MaxPooling2D)     (None, 3, 3, 512)    0           ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 4608)         0           ['block5_pool[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          2359808     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 128)          65664       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 64)           8256        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 18)           1170        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 17,149,586\n",
            "Trainable params: 17,149,586\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "opt = keras.optimizers.Adam(learning_rate = lr)\n",
        "model.compile(loss='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
        "train = model.fit(X_train, Y_train, validation_data = (X_val, Y_val), epochs = 50, batch_size = 32, verbose = 1)  "
      ],
      "metadata": {
        "id": "lFyXeFFAkmqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test \n",
        "test_path = \"/content/AIDE dataset/test\"\n",
        "X_test = []\n",
        "Y_test = []\n",
        "for label_folder in os.listdir(test_path):\n",
        "  curr_path = os.path.join(test_path, label_folder)\n",
        "  lbl = list_categories.index(label_folder)\n",
        "  for img_name in os.listdir(curr_path):\n",
        "    img = cv2.imread(os.path.join(curr_path, img_name), cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, None, fx = 0.5, fy = 0.5)\n",
        "    X_test.append(img)\n",
        "    Y_test.append(int(lbl))\n",
        "X_test = np.array(X_test) / 255.0\n",
        "Y_test = np.array(Y_test)\n",
        "\n",
        "Y_test = to_categorical(Y_test)"
      ],
      "metadata": {
        "id": "WAlfRNcCLnXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"Loss = \", test_loss)\n",
        "print(\"Evaluation Accuracy = \", test_accuracy * 100)"
      ],
      "metadata": {
        "id": "JEXJXYdGkq8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(X_test.shape[0]):\n",
        "  pred = model.predict(X_test[i].reshape(1, 112, 112, 1))\n",
        "  pred = list_categories[np.argmax(pred)]\n",
        "  true = list_categories[np.argmax(Y_test[i])]\n",
        "  if pred == true:\n",
        "    count += 1\n",
        "print(f\"Test Accuracy: {count / X_test.shape[0]}\")"
      ],
      "metadata": {
        "id": "XYL80DbzLsI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = train.history['accuracy']\n",
        "val_accuracy = train.history['val_accuracy']\n",
        "epochs = range(len(accuracy))\n",
        "plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m3XTsSHpkvzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = train.history['loss']\n",
        "val_loss = train.history['val_loss']\n",
        "epochs = range(len(train_loss))\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hwF2LvK-kv42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(f\"/content/gdrive/MyDrive/AI Draw Equation/Model/VGG16 lr={lr}.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(f\"/content/gdrive/MyDrive/AI Draw Equation/Model/VGG16 lr={lr}.h5\")"
      ],
      "metadata": {
        "id": "EJhG1T-akyf9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}